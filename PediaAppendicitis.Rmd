---
title: "Exploring Pediatric Appendicitis"
author: "Muhammad Alakhdar"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  fig.align = "center"
)
```

```{r include=FALSE}
#| label: Loading required packages

library(tidyverse)
library(tidymodels)
library(scales)
library(ggthemes)
library(readxl)
library(knitr)
library(kableExtra)
library(janitor)
```

# Introdution

[In 2015, approximately 11.6 million cases of appendicitis were reported, resulting in around 50,100 deaths worldwide.](https://doi.org/10.1016/S0140-6736(16)31012-1) Also appendicitis is one of the most common and significant causes of sudden abdominal pain, So diagnosing and treating this disease should be made as quickly as possible. There are many criteria to do so such as taking a history, physical examination, risk scores (e.g Alvarado Score) and imaging techiqies like ultra-sonography and CT.

The cost of the diagnosis could be improved for example using US instead of CT, accuracy could be also improved using Machine learning. [One recent study built a model to predict appendicitis in pediatrics using Interpretable unsupervised machine learning method](https://doi.org/10.1016/j.media.2023.103042).

[Since a lot of models has been built using just history and physical examinatin as predictors, we would use the same dataset to explore the disease for a bit then build models that focus on ultra-sonography as a way to diagnose appendicitis.](https://doi.org/10.5281/zenodo.7711412)

# Methodology

```{r include=FALSE}
#| label: Loading pediatric appendicitis dataset
pedia_appen_raw <- read_excel("data/app_data.xlsx",
  sheet = 1
)
```

-   Taking a look at the data

```{r echo=FALSE}
#| label: A sample look of the dataset

pedia_appen_raw |>
  drop_na(Sex, US_Performed, Severity, Management, Diagnosis) |>
  select(Sex, US_Performed, Severity, Management, Diagnosis) |>
  sample_n(10) |>
  kable(
    caption = "First Ten Rows of the Pediatric Appendicitis Dataset"
  )
```

## Some Plots

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Distribution of the Patients's Age by Gender"}
#| label: A histogram for the age


pedia_appen_raw |>
  drop_na(Age, Sex) |>
  ggplot(aes(x = Age)) +
  geom_histogram(color = "white", binwidth = .3) +
  labs(
    x = "Age",
    y = "Count",
    title = "Distribution of the Patients's Age by Gender"
  ) +
  facet_wrap(~Sex) +
  theme_minimal()


pedia_appen_raw |>
  drop_na(Age, Sex) |>
  group_by(Sex) |>
  summarize(
    Mean = round(mean(Age), 2)
  ) |>
  kable(
    caption = "The Mean Age of Patients By Gender"
  ) |>
  kable_styling(latex_options = c("hold_position", "striped"))
```

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Prevalence of Appendicitis by Gender"}
#| label: A Bar plot for the Diagnosis


pedia_appen_raw |>
  drop_na(Sex, Diagnosis) |>
  ggplot(aes(x = Diagnosis, fill = Sex)) +
  geom_bar(position = "fill") +
  labs(
    x = "Diagnosis",
    y = "Prop",
    title = "prevalence of Appendicitis by Gender",
    fill = "Gender"
  ) +
  theme(
    legend.position = c(0.4, 0.93),
    legend.direction = "horizontal",
    legend.key.size = unit(0.2, "cm"),
    legend.key.height = unit(0.1, "cm"),
    legend.text.align = 0,
    legend.background = element_rect(color = "black", linewidth = 0.2),
    legend.text = element_text(size = 7),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    plot.caption = element_text(size = 8, hjust = 0)
  ) +
  guides(fill = guide_legend(nrow = 1)) +
  theme_minimal() +
  scale_fill_colorblind()

pedia_appen_raw |>
  drop_na(Sex, Diagnosis) |>
  count(Sex, Diagnosis) |>
  group_by(Sex) |>
  mutate(
    p = round(n / sum(n), 2)
  ) |>
  kable(
    caption = "Prevalence of Appendicitis by Gender"
  )
```

-   Figure 2 shows that the prevalence in the appendicitis is more males than females which is consistent with existing finding, but it is not substantial.

```{r fig.cap="Alvarado Risk Score .vs Appendicitis Diagnosis"}
pedia_appen_raw |>
  drop_na(Alvarado_Score, Diagnosis, Severity) |>
  ggplot(aes(x = Diagnosis, y = Alvarado_Score)) +
  geom_boxplot(aes(fill = Diagnosis)) +
  labs(
    title = "Alvarado Risk Score .vs Appendicitis Diagnosis",
    subtitle = "Diagnosis by Severity",
    x = "Diagnosis",
    y = "Avarado Score"
  ) +
  facet_wrap(~Severity) +
  scale_fill_colorblind() +
  theme_minimal()

pedia_appen_raw |>
  drop_na(Alvarado_Score, Diagnosis) |>
  group_by(Diagnosis) |>
  summarize(
    mean = mean(Alvarado_Score)
  ) |>
  kable(
    caption = "Alvarado Risk Score .vs Appendicitis Diagnosis"
  )
```

-   Alvarado score is a system that have been developed to identify people who are likely to have appendicitis, like a score below 5 suggests against a diagnosis of appendicitis, whereas a score of 7 or more is predictive of acute appendicitis, but it is performance varies. Here added the severity diagnosis to see if the score differs also.

```{r fig.cap="Diagnosis of Appendicitis .vs UltraSonography"}
pedia_appen_raw |>
  drop_na(Diagnosis, US_Performed) |>
  ggplot(aes(x = US_Performed, fill = Diagnosis)) +
  geom_bar(position = "fill") +
  labs(
    title = "Diagnosis of Appendicitis .vs UltraSonography",
    subtitle = "Divided by if US is Performed or Not",
    x = "Diagnosis"
  ) +
  scale_fill_colorblind() +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5),
    axis.title.x = element_text(margin = margin(t = 10)),
    axis.title.y = element_text(margin = margin(r = 10))
  ) +
  theme_minimal()
```

-   In cases where the diagnosis is unclear, other methods are preferred like medical imaging for example (CT, US), CT is more accurate but it is expensive and has some side effects, US may be preferred as the first imaging test in children and pregnant women because of the risks associated with radiation exposure from CT scans.

```{r fig.cap="Severity of Appendicitis .vs Appendicular Abscess	"}
#| label: Severity of the appendicits


pedia_appen_raw |>
  drop_na(Severity, Appendicular_Abscess) |>
  ggplot(aes(x = Severity, fill = Appendicular_Abscess)) +
  geom_bar(position = "fill") +
  labs(
    x = "Severity",
    y = "Prop",
    title = "Severity of Appendicitis .vs Appendicular Abscess",
    col = "Appendicular Abscess"
  ) +
  theme_minimal() +
  scale_fill_colorblind()
```

```{r fig.cap="Appendix Diameter .vs Appendicitis Type of Management"}
pedia_appen_raw |>
  drop_na(Appendix_Diameter, Management, Severity) |>
  ggplot(aes(y = Management, x = Appendix_Diameter)) +
  geom_boxplot(aes(fill = Management)) +
  labs(
    title = "Appendix Diameter .vs Appendicitis Type of Management",
    subtitle = "Media Diameter",
    x = "Management",
    y = "Appendix Diameter"
  ) +
  facet_wrap(~Severity) +
  scale_fill_colorblind() +
  theme_minimal()

pedia_appen_raw |>
  drop_na(Appendix_Diameter, Management) |>
  group_by(Management) |>
  summarize(
    mean = round(mean(Appendix_Diameter), 2)
  ) |>
  kable(
    caption = "Mean of Appendix Diameter By Appendicitis Management"
  )
```

## Statistical Analysis

### Hypothesis testing

Since the use of ultrasound is less expensive and less harmful than CT, we would test if only the introduction of US in the diagnostic process will have a discernible (i.e. significant) difference on the outcome of the diagnosis.

- To do this, we will use a hypothesis testing framework and set our level of rejection to be 0.05.

1. $$Null~hypothesis$$ There is no difference in the proportion of the outcome if only the US has been used.

2. $$Alternative~hypothesis$$ There is a difference in the proportion of the outcome if only the US has been used.



```{r echo=FALSE}
#| label: hypothsis testing with randomization

set.seed(202025)

pedia_appen_test <- pedia_appen_raw |>
  drop_na(US_Performed, Diagnosis)

obs_stat <- pedia_appen_test |>
  specify(Diagnosis ~ US_Performed, success = "no appendicitis") |>
  calculate(stat = "diff in props", order = c("yes", "no"))

null_dist <- pedia_appen_raw |>
  drop_na(US_Performed, Diagnosis) |>
  specify(Diagnosis ~ US_Performed, success = "no appendicitis") |>
  hypothesize(null = "independence") |>
  generate(reps = 1000, type = "permute") |>
  calculate(stat = "diff in props", order = c("yes", "no"))

pvale <- null_dist |>
  get_p_value(obs_stat = obs_stat, direction = "two sided")
```



- Since is p-value is `r round(pvale$p_value, 2)` which bigger than 0.05, we fail to reject null hypothesis.
So the data does not provide a convincing evidence that only the introduction of US will have a have a discernible difference on the outcome of the diagnosis.



```{r echo=FALSE}
#| label: confidence interval1

set.seed(202025)

boot_dist <- pedia_appen_test |>
  specify(response = Diagnosis, explanatory = US_Performed, success = "appendicitis") |>
  generate(reps = 1000, type = "bootstrap") |>
  calculate(stat = "diff in props", order = c("yes", "no"))

ci <- boot_dist |>
  get_ci()

ci |>
  kable(
    digits = 2,
    caption = "95% Confidence interval for difference in appendicitis diagnosis when ultrasonography is performed"
  )
```



- What if we use the results that came from the US, we check if adding **Appendix Diameter** will have a discernible difference on the outcome of the diagnosis.

- So our hypotheses are
1. $$Null~hypothesis$$ There is no difference in the proportion of results when appendix diameter results from US are added.

2. $$Alternative~hypothesis$$ There is a difference in the proportion of the outcome when the appendix diameter results from US is added.



```{r echo=FALSE, warning=FALSE}
#| label: hypothsis testing with randomization between diagnosis and appendix diameter

set.seed(202025)

pedia_appen_test2 <- pedia_appen_raw |>
  drop_na(Appendix_Diameter, Diagnosis)

obs_stat2 <- pedia_appen_test2 |>
  specify(Appendix_Diameter ~ Diagnosis) |>
  calculate(stat = "diff in means", order = c("appendicitis", "no appendicitis"))

null_dist2 <- pedia_appen_test2 |>
  specify(Appendix_Diameter ~ Diagnosis) |>
  hypothesize(null = "independence") |>
  generate(reps = 1000, type = "permute") |>
  calculate(stat = "diff in means", order = c("appendicitis", "no appendicitis"))

pvale2 <- null_dist2 |>
  get_p_value(obs_stat = obs_stat2, direction = "two sided")
```


- Since the p-value is `r round(pvale2, 2)`, which is less than 0.05, then we reject the null hypothesis, so the data provide convincing evidence that adding **Appendix diameter** will have a discernible difference on the outcome of the diagnosis.



```{r echo=FALSE}
#| label: confidence interval

set.seed(202025)

boot_dist2 <- pedia_appen_test2 |>
  specify(response = Appendix_Diameter, explanatory = Diagnosis) |>
  generate(reps = 1000, type = "bootstrap") |>
  calculate(stat = "diff in means", order = c("appendicitis", "no appendicitis"))

ci2 <- boot_dist2 |>
  get_ci()

ci2 |>
  kable(
    digits = 2,
    caption = "95% confidence interval for the difference in mean between \n patients diagnosed with appendicitis or no appendicitis."
  )
```



### Modeling

- To help the health workers make more informed decisions (i.e, Accurately diagnosing the appendicitis) we would use machine learning.

We will build Supervised explainable models like logistic regression then test and validate the model.


So we will use **cross validation** as way to build the model then we would use **ROC** to check the models precision and accuracy.


```{r include=FALSE}
#| label: preparing the dataset for the model
set.seed(22025)

pedia_appen1 <- pedia_appen_raw |>
  drop_na(
    Diagnosis, Alvarado_Score, US_Performed,
    Appendix_Diameter, Weight, BMI
  ) |>
  mutate(
    Diagnosis = factor(
      Diagnosis
    ),
    US_Performed = factor(
      US_Performed
    ),
    BMI = as.numeric(BMI)
  )

unique(pedia_appen1$US_Performed)

pedia_appen_split <- initial_split(pedia_appen1, prop = 0.8)

pedia_appen_training <- training(pedia_appen_split)
pedia_appen_test <- testing(pedia_appen_split)
```

```{r include=FALSE}
#| label: training the model0
set.seed(22025)

pedia_appen_model <- logistic_reg() |>
  fit(Diagnosis ~ Alvarado_Score, data = pedia_appen_training)

tidy(pedia_appen_model)
```

```{r echo=FALSE}
#| label: Testing pediatric appendicitis model0

pedia_appen_aug <- augment(pedia_appen_model,
  new_data = pedia_appen_test
)

pedia_appen_aug |>
  sample_n(10) |>
  clean_names() |>
  select(pred_class, pred_appendicitis, pred_no_appendicitis, alvarado_score) |>
  kable(
    digits = 2,
    caption = "A Model to Diagnose Appendicitis With Avarado Score"
  )
```



```{r echo=FALSE}
#| label: model evaluation0

pedia_appen_aug |>
  count(.pred_class, Diagnosis) |>
  arrange(Diagnosis) |>
  group_by(Diagnosis) |>
  mutate(
    p = round(n / sum(n), 2),
    decision = case_when(
      .pred_class == "appendicitis" & Diagnosis == "appendicitis" ~ "True positive",
      .pred_class == "appendicitis" & Diagnosis == "no appendicitis" ~ "False positive",
      .pred_class == "no appendicitis" & Diagnosis == "appendicitis" ~ "False negative",
      .pred_class == "no appendicitis" & Diagnosis == "no appendicitis" ~ "True negative"
    )
  ) |>
  kable(
    caption = "Precision and Accuracy of Model to Diagnose Appendicitis With Avarado Score"
  )
```

```{r echo=FALSE}
#| label: model eval0

pedia_appen_roc <-
  roc_curve(
    pedia_appen_aug,
    truth = Diagnosis,
    .pred_appendicitis
  )

ggplot(pedia_appen_roc, aes(x = 1 - specificity, y = sensitivity)) +
  geom_path() +
  geom_abline(lty = 3) +
  coord_equal()
```



```{r include=FALSE}
#| label: training the model
set.seed(22025)
pedia_appen_model1 <- logistic_reg() |>
  fit(Diagnosis ~ Alvarado_Score +
    Appendix_Diameter + Weight + BMI, data = pedia_appen_training)


tidy(pedia_appen_model1)
```

```{r echo=FALSE}
#| label: Testing pediatric appendicitis model

pedia_appen_aug1 <- augment(pedia_appen_model1,
  new_data = pedia_appen_test
)

pedia_appen_aug1 |>
  sample_n(10) |>
  clean_names() |>
  select(pred_class, pred_appendicitis, pred_no_appendicitis) |>
  kable(
    digits = 2,
    caption = "A Model to Diagnose Appendicitis With Avarado Score, Appendix_Diameter, Weight and BMI"
  )
```

```{r echo=FALSE}
#| label: model evaluation

pedia_appen_aug1 |>
  count(.pred_class, Diagnosis) |>
  arrange(Diagnosis) |>
  group_by(Diagnosis) |>
  mutate(
    p = round(n / sum(n), 2),
    decision = case_when(
      .pred_class == "appendicitis" & Diagnosis == "appendicitis" ~ "True positive",
      .pred_class == "appendicitis" & Diagnosis == "no appendicitis" ~ "False positive",
      .pred_class == "no appendicitis" & Diagnosis == "appendicitis" ~ "False negative",
      .pred_class == "no appendicitis" & Diagnosis == "no appendicitis" ~ "True negative"
    )
  ) |>
  kable(
    caption = "Precision and Accuracy of Model to Diagnose Appendicitis With Avarado Score, Appendix_Diameter, Weight and BMI"
  )
```

```{r echo=FALSE}
#| label: model eval

pedia_appen_roc1 <-
  roc_curve(
    pedia_appen_aug1,
    truth = Diagnosis,
    .pred_appendicitis
  )

ggplot(pedia_appen_roc1, aes(x = 1 - specificity, y = sensitivity)) +
  geom_path() +
  geom_abline(lty = 3) +
  coord_equal()
```

```{r echo=FALSE, fig.cap="Comparing the Accuracy and Precision of both Models"}
#| label: Comparing models

pedia_appen_roc <- pedia_appen_roc |>
  mutate(model = "Model1")

pedia_appen_roc1 <- pedia_appen_roc1 |>
  mutate(model = "Model2")
bind_rows(
  pedia_appen_roc,
  pedia_appen_roc1
) |>
  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +
  geom_path() +
  geom_abline(lty = 3) +
  coord_equal()
```


- The second model that used **Ultra-sonography** results showed lower **False positives and negatives**. per table above.


### Diagnosing

```{r echo=FALSE}
#| label: Predicting appendicitis outcome

case <- tibble(Alvarado_Score = 6, Appendix_Diameter = 10, Weight = 30, BMI = 20)


predict(pedia_appen_model1, case, type="prob")
```

